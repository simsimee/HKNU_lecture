{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-commnity\n",
    "!pip install -U gradio\n",
    "!pip install serpapi\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dd15d",
   "metadata": {},
   "source": [
    "## query expansion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175939c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "# âœ… ë©”ì¸ LLM (ì‘ë‹µ + Expansion ê³µìš©)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=1.0,\n",
    "    model='gpt-4o-mini',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# âœ… ë©”ì¸ ì‘ë‹µ í•¨ìˆ˜\n",
    "def response(message, history, additional_input_info):\n",
    "    history_langchain_format = []\n",
    "    history_langchain_format.append(SystemMessage(content=additional_input_info))\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "    history_langchain_format.append(HumanMessage(content=message))\n",
    "\n",
    "    stream = llm.stream(history_langchain_format)\n",
    "\n",
    "    full_content = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.content:\n",
    "            full_content += chunk.content\n",
    "            yield full_content\n",
    "\n",
    "# âœ… LLM ê¸°ë°˜ Query Expansion\n",
    "def expand_query(user_query):\n",
    "    expansion_prompt = f\"\"\"ì•„ë˜ ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë” ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ í™•ì¥í•´ì¤˜. ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ì‘ì„±í•˜ê³  ë°”ë¡œ ë³µì‚¬ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì‘ì„±í•´ì¤˜. ì„¤ëª…ì„ ì œì™¸í•˜ê³  ìœ ì €ê°€ ë°”ë¡œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸° í•  í”„ë¡¬í”„íŠ¸ëŠ” [ë³€ê²½ëœ í”„ë¡¬í”„íŠ¸] ì•„ë˜ì— ì‘ì„±í•´ì¤˜.\n",
    "ì‚¬ìš©ì ì¿¼ë¦¬:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "    messages = [HumanMessage(content=expansion_prompt)]\n",
    "    stream = llm.stream(messages)\n",
    "\n",
    "    full_content = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.content:\n",
    "            full_content += chunk.content\n",
    "            yield full_content\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë¡œì„œ ì–´ë¦° ì´ˆë“±í•™ìƒì˜ ì§ˆë¬¸ì„ ë°›ê²Œ ë©ë‹ˆë‹¤. ì´ˆë“±í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìµœëŒ€í•œ ìì„¸í•˜ê³  í’ë¶€í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ ì¹œì ˆí•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”. ê°€ëŠ¥í•œ ê²½ìš° ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ì—¬ ì¹œê·¼í•¨ì„ ë”í•˜ë„ë¡ í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    # âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë§¨ ìœ„\n",
    "    extra_input = gr.Textbox(\n",
    "        value=system_prompt,\n",
    "        label=\"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\",\n",
    "        placeholder=\"ì–´ë¦°ì´ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”\"\n",
    "    )\n",
    "\n",
    "    # âœ… ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ (ì¤‘ì•™)\n",
    "    chat = gr.ChatInterface(\n",
    "        fn=response,\n",
    "        additional_inputs=[extra_input],\n",
    "        title=\"ë‚˜ë§Œì˜ ì±—ë´‡\",\n",
    "        description=\"ë‚˜ë§Œì˜ ì±—ë´‡ìœ¼ë¡œ Customizingí•˜ì—¬ ëŒ€í™”í•˜ê¸°!\",\n",
    "        submit_btn=\"ë³´ë‚´ê¸° ğŸ“¨\",\n",
    "        stop_btn=\"ë©ˆì¶”ê¸° â¹ï¸\",\n",
    "    )\n",
    "\n",
    "    # âœ… ì˜ˆì‹œ\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"ì•ˆë…•, ë°˜ê°€ì›Œ!\"],\n",
    "            [\"ìš”ì¦˜ ë‚ ì”¨ ë¥ë‹¤ ã… ã… ,ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜\"],\n",
    "            [\"í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì´ ë­”ì§€ ì•Œì•„? ì•Œë©´ íŒŒì´ì¬ìœ¼ë¡œ ì½”ë”©í•´ì¤˜\"]\n",
    "        ],\n",
    "        inputs=chat.textbox,\n",
    "        label=\"Examples (í´ë¦­í•˜ë©´ ì…ë ¥ì°½ìœ¼ë¡œ ë³µì‚¬ë©ë‹ˆë‹¤)\"\n",
    "    )\n",
    "\n",
    "    # âœ… Query Expansionì€ ë§¨ ì•„ë˜\n",
    "    with gr.Accordion(label=\"ğŸ’¡ Query Expansion (LLM ê¸°ë°˜)\", open=True):\n",
    "        user_input = gr.Textbox(label=\"ì›ë³¸ ë©”ì‹œì§€\", placeholder=\"í™•ì¥í•  ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "        expanded_output = gr.Textbox(label=\"í™•ì¥ëœ ë©”ì‹œì§€\", interactive=True)\n",
    "        expand_btn = gr.Button(\"Query Expansion ì‹¤í–‰\")\n",
    "        expand_btn.click(\n",
    "            fn=expand_query,\n",
    "            inputs=user_input,\n",
    "            outputs=expanded_output\n",
    "        )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c0994",
   "metadata": {},
   "source": [
    "## ì¸í„°ë„· ê²€ìƒ‰ ì—°ë™ API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f93235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.utilities.serpapi import SerpAPIWrapper\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "# âœ… í™˜ê²½ ë³€ìˆ˜\n",
    "# os.environ['OPENAI_API_KEY'] = ''\n",
    "# os.environ['SERPAPI_API_KEY'] = ''\n",
    "\n",
    "# âœ… ë©”ì¸ LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=1.0,\n",
    "    model='gpt-4o-mini',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# âœ… SerpAPI Wrapper\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "# âœ… ë©”ì¸ ì‘ë‹µ í•¨ìˆ˜\n",
    "def response(message, history, additional_input_info, search_enabled):\n",
    "    history_langchain_format = [SystemMessage(content=additional_input_info)]\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "    history_langchain_format.append(HumanMessage(content=message))\n",
    "\n",
    "    if search_enabled:\n",
    "        extract_prompt = f\"ì•„ë˜ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì§§ê²Œ ì¶”ì¶œí•´ì¤˜. ê²€ìƒ‰ APIì— ì „ë‹¬í•´ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•  ë•Œ ì‚¬ìš©í• ê±°ì•¼:\\n{message}\"\n",
    "        keywords = llm([HumanMessage(content=extract_prompt)]).content\n",
    "        print(f\"[ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼]: {keywords}\")\n",
    "\n",
    "        search_result = search.run(keywords)\n",
    "        print(f\"[ğŸ” SerpAPI ê²€ìƒ‰ ê²°ê³¼]: {search_result}\")  # âœ… ê²°ê³¼ ì¶œë ¥\n",
    "\n",
    "        search_info = f\"[ê²€ìƒ‰ í‚¤ì›Œë“œ]: {keywords}\\n[ê²€ìƒ‰ ê²°ê³¼]: {search_result}\"\n",
    "        history_langchain_format.insert(1, SystemMessage(content=search_info))\n",
    "\n",
    "    stream = llm.stream(history_langchain_format)\n",
    "    full_content = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.content:\n",
    "            full_content += chunk.content\n",
    "            yield full_content\n",
    "\n",
    "# âœ… Query Expansion (ìŠ¤íŠ¸ë¦¼)\n",
    "def expand_query(user_query):\n",
    "    expansion_prompt = f\"\"\"ì•„ë˜ ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë” ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ í™•ì¥í•´ì¤˜. ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ì‘ì„±í•˜ê³  ë°”ë¡œ ë³µì‚¬ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì‘ì„±í•´ì¤˜. ì„¤ëª…ì„ ì œì™¸í•˜ê³  ìœ ì €ê°€ ë°”ë¡œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸° í•  í”„ë¡¬í”„íŠ¸ëŠ” [ë³€ê²½ëœ í”„ë¡¬í”„íŠ¸] ì•„ë˜ì— ì‘ì„±í•´ì¤˜.\n",
    "ì‚¬ìš©ì ì¿¼ë¦¬:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "    stream = llm.stream([HumanMessage(content=expansion_prompt)])\n",
    "    full_content = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.content:\n",
    "            full_content += chunk.content\n",
    "            yield full_content\n",
    "\n",
    "system_prompt = \"\"\"ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë¡œì„œ ì–´ë¦° ì´ˆë“±í•™ìƒì˜ ì§ˆë¬¸ì„ ë°›ê²Œ ë©ë‹ˆë‹¤. ì´ˆë“±í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìµœëŒ€í•œ ìì„¸í•˜ê³  í’ë¶€í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ ì¹œì ˆí•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”. ê°€ëŠ¥í•œ ê²½ìš° ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ì—¬ ì¹œê·¼í•¨ì„ ë”í•˜ë„ë¡ í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    # âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ìƒë‹¨ ê³ ì •\n",
    "    extra_input = gr.Textbox(\n",
    "        value=system_prompt,\n",
    "        label=\"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\"\n",
    "    )\n",
    "    system_prompt_state = gr.State(system_prompt)\n",
    "\n",
    "    # âœ… ê²€ìƒ‰ í† ê¸€ â†’ ìœ ì € ì…ë ¥ì°½ ë°”ë¡œ ì•„ë˜\n",
    "    search_toggle = gr.Checkbox(label=\"ì¸í„°ë„· ê²€ìƒ‰ ì‚¬ìš© (SerpAPI)\", value=False)\n",
    "\n",
    "    chat = gr.ChatInterface(\n",
    "        fn=response,\n",
    "        additional_inputs=[system_prompt_state, search_toggle],\n",
    "        title=\"ë‚˜ë§Œì˜ ì±—ë´‡\",\n",
    "        description=\"ë‚˜ë§Œì˜ ì±—ë´‡ìœ¼ë¡œ Customizingí•˜ì—¬ ëŒ€í™”í•˜ê¸°!\",\n",
    "        submit_btn=\"ë³´ë‚´ê¸° ğŸ“¨\",\n",
    "        stop_btn=\"ë©ˆì¶”ê¸° â¹ï¸\",\n",
    "    )\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"ì„¸ê³„ì—ì„œ ê°€ì¥ ë†’ì€ ì‚°ì€?\"],\n",
    "            [\"ìµœì‹  AI ë‰´ìŠ¤ ì•Œë ¤ì¤˜\"],\n",
    "            [\"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\"]\n",
    "        ],\n",
    "        inputs=chat.textbox,\n",
    "    )\n",
    "\n",
    "    # âœ… Query Expansion\n",
    "    with gr.Accordion(label=\"ğŸ’¡ Query Expansion (LLM ê¸°ë°˜)\", open=True):\n",
    "        user_input = gr.Textbox(label=\"ì›ë³¸ ë©”ì‹œì§€\")\n",
    "        expanded_output = gr.Textbox(label=\"í™•ì¥ëœ ë©”ì‹œì§€\", interactive=True)\n",
    "        expand_btn = gr.Button(\"Query Expansion ì‹¤í–‰\")\n",
    "        expand_btn.click(\n",
    "            fn=expand_query,\n",
    "            inputs=user_input,\n",
    "            outputs=expanded_output\n",
    "        )\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
